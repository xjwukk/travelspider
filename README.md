# 项目简介

本项目使用 Python 中的 Scrapy 框架爬取数据，并使用 Jupyter Notebook 进行简单的数据清洗和处理。

## Scrapy 项目结构

Scrapy 项目通常包含以下几个部分：

- **spiders**：定义爬虫的模块。
- **items**：定义要提取的数据结构。
- **pipelines**：处理提取到的数据（如存储到数据库）。
- **middlewares**：请求和响应的处理逻辑。

![Scrapy 项目结构](https://github.com/user-attachments/assets/d9d85096-8fde-42a2-9f45-873a8a1a60d7)

## 数据探索与清洗

在数据处理过程中，我们对数据进行了探索与清洗。数据探索与清洗的具体实现：

![数据探索与清洗示例1](https://github.com/user-attachments/assets/ea0059d9-8a4c-4c30-8bee-43043f98acf4)
![数据探索与清洗示例2](https://github.com/user-attachments/assets/e5557638-bbdb-4a99-a023-e1c26adc7af2)
![数据探索与清洗示例3](https://github.com/user-attachments/assets/772d505d-b266-4fd5-9bb9-dd3051c285db)

